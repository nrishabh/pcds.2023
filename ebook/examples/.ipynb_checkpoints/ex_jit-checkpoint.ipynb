{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184a7195-3a54-4e32-b975-f8003ad793ac",
   "metadata": {},
   "source": [
    "### Python and Just-in-Time Compilation:\n",
    "\n",
    "This is a quick lecture to take a look at the ways to improve the performance of interpreted code. We have been working with compiled code with OpenMP in C, so now let's jump back to interpreted code in Python.\n",
    "\n",
    "* _Compilation_ is the process of generating machine code that can be run directly on a processor from source code written in a programming language.\n",
    "\n",
    "* _Interpreters_ are programs that directly execute instructions written in a programming language without compilation.\n",
    "\n",
    "There is a lot of gray area and confusion and reality will often blend these concepts. Let's consider the Java landscape. Java source code is _compiled_ into a intermediate representation (Java byte code) that run through some combination of:\n",
    "  * a Java _interpreter_ that translates Java byte code to machine instructions\n",
    "  * a just-in-time (JIT) compiler that translates byte code into machine code as the program executes\n",
    "  \n",
    "Java ends up being a compiled language from a programmer's perspective. The interpreter provides portability.\n",
    "\n",
    "The concept of just-in-time compilation on interpreted languages is powerful in that it can realize the performance of compiled code while preserving the flexibility and ease of programming in interpreted code. Python has a JIT and we will explore performance of JIT compilation and its interaction with parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c350c0-0b98-4d9c-915e-0de7e91c0697",
   "metadata": {},
   "source": [
    "#### Mutual Web Outlinks Example\n",
    "\n",
    "Returning to our Web Outlinks example. Let's start with a review of \n",
    "  * building a small graph\n",
    "  * building a larger graph \n",
    "  * the serial mutual outlinks program\n",
    "  * a `joblib` parallelized outlinks program (based on processes)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f1996f-32bd-486c-b9b4-37e524a9acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "G = nx.erdos_renyi_graph(5,0.8, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b098c-bdfe-4c58-9b82-37aadcb2c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(G, pos=nx.spring_layout(G), with_labels=False, node_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72edd3ac-2ea7-4539-9daa-c8a29454d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmat = nx.to_numpy_matrix(G)\n",
    "\n",
    "outmat = np.zeros(gmat.shape, dtype=np.float32)\n",
    "\n",
    "for i in range(gmat.shape[0]):\n",
    "    for j in range(i+1,gmat.shape[1]):        \n",
    "        outmat[i,j] = np.dot(np.asarray(gmat[i,:]).reshape(-1), np.asarray(gmat[j,:]).reshape(-1))\n",
    "outmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe8c69-6f42-4b2c-ad10-837f6f59f375",
   "metadata": {},
   "source": [
    "Now generate a big graph and we'll start our performance analysis. Let's look at a serial version on a graph with 1000 nodes and about 5 outbound edges per node. \n",
    "\n",
    "Serial program to calculate mutual outlinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0c01a-c72b-40bb-95b3-d378cd84cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycles disappear when p = log(n)/n\n",
    "G= nx.erdos_renyi_graph(1000,0.01,directed=True)\n",
    "nx.draw_networkx(G, pos=nx.spring_layout(G), with_labels=False, node_size=10)\n",
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074ae760-a2b4-4bdb-94f2-419eeed3f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "gmat = nx.to_numpy_matrix(G)\n",
    "\n",
    "outmat = np.zeros(gmat.shape)\n",
    "\n",
    "for i in range(gmat.shape[0]):\n",
    "    for j in range(i+1,gmat.shape[1]):        \n",
    "        outmat[i,j] = np.dot(np.asarray(gmat[i,:]).reshape(-1), np.asarray(gmat[j,:]).reshape(-1))\n",
    "        \n",
    "np.count_nonzero(outmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83283a87-e7a0-4cb1-b218-d288e1627a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for i in range(gmat.shape[0]):\n",
    "    for j in range(i+1,gmat.shape[1]):        \n",
    "        outmat[i,j] = np.dot(np.asarray(gmat[i,:]).reshape(-1), np.asarray(gmat[j,:]).reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d95355-4aa5-43c6-bc5d-572d09766c32",
   "metadata": {},
   "source": [
    "That's a serial implementation. Let's parallelize it with `joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c6cc5-4388-4e8d-a30a-acd384201d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_loop(i):\n",
    "    partial_out = np.zeros(gmat.shape[1])\n",
    "    for j in range(i+1,gmat.shape[1]):    \n",
    "        partial_out[j] = np.dot(np.asarray(gmat[i,:]).reshape(-1), np.asarray(gmat[j,:]).reshape(-1))    \n",
    "    return partial_out\n",
    "    \n",
    "from joblib import Parallel, delayed\n",
    "partials = Parallel(n_jobs=4)(delayed(inner_loop)(i) for i in range(gmat.shape[0]))\n",
    "\n",
    "outmat = np.array(partials)\n",
    "np.count_nonzero(outmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c54697-c993-4dc3-8c92-4dc06e7305ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "and time it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af36d0-3717-43cd-bd4a-f9bf63718eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "partials = Parallel(n_jobs=4)(delayed(inner_loop)(i) for i in range(gmat.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087251e6-f2f9-41bd-a0b4-5d0537c839e7",
   "metadata": {},
   "source": [
    "OK, this is where we stopped in Lecture 2.\n",
    "\n",
    "### Numba \n",
    "\n",
    "Numba is an open source JIT compiler that translates a subset of Python and NumPy code into fast machine code.  Let's look at the outcome of compiling the inner loop of our serial implementation. This should reduce the number of calls to the interpret to be O(rows) rather than O(rows*columns).\n",
    "\n",
    "Read the 5-minute guide to Numba (https://numba.readthedocs.io/en/stable/user/5minguide.html)\n",
    "  then do the following:\n",
    "* import the numba jit\n",
    "* add numba symbols and decorators to compile inner loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fed16b-4fd5-40d3-8497-e1779c7badad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "outmat = np.zeros(gmat.shape)\n",
    "\n",
    "# TODO\n",
    "def comp_inner_loop(i):\n",
    "    partial_out = np.zeros(gmat.shape[1])\n",
    "    for j in range(i+1,gmat.shape[1]):    \n",
    "        partial_out[j] = np.dot(np.asarray(gmat[i,:]).reshape(-1), np.asarray(gmat[j,:]).reshape(-1))  \n",
    "    return partial_out\n",
    "    \n",
    "for i in range(gmat.shape[0]):\n",
    "    outmat[i,:] = comp_inner_loop(i)\n",
    "\n",
    "np.count_nonzero(outmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd3eba-fad1-4daf-abde-a144eb70122b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for i in range(gmat.shape[0]):\n",
    "    outmat[i,:] = comp_inner_loop(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0cce9c-e979-4d7b-b402-67a626056b16",
   "metadata": {},
   "source": [
    "#### Numba and parallel for loops\n",
    "\n",
    "OK, that is great. Let's try to compile the whole thing and add parralellism to the outer loop. You will need to check out explicit parallelization at https://numba.readthedocs.io/en/stable/user/parallel.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b2916-7a94-4a17-91dd-b1589aab2feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# TODO\n",
    "def comp_inner_loop(i):\n",
    "    partial_out = np.zeros(gmat.shape[1])\n",
    "    for j in range(i+1,gmat.shape[1]):    \n",
    "        partial_out[j] = np.dot(np.asarray(gmat[i,:]).reshape(-1), np.asarray(gmat[j,:]).reshape(-1))  \n",
    "   # print(partial_out)\n",
    "    return partial_out\n",
    "\n",
    "# TODO\n",
    "def comp_outerloop(outmat):\n",
    "\n",
    "    for i in TODO range TODO (gmat.shape[0]):\n",
    "        outmat[i,:] = comp_inner_loop(i)\n",
    "\n",
    "\n",
    "outmat = np.zeros(gmat.shape)\n",
    "comp_outerloop(outmat)\n",
    "np.count_nonzero(outmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c414144-6a27-4b0c-b272-cc6afd493dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "comp_outerloop(outmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fea2a0-d921-41ab-8e20-b19019c0b711",
   "metadata": {},
   "source": [
    "OK that was pretty awesome. >3x speedup over compiled code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3161c2e-1e1a-41ee-9f18-ad642cbc8452",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "Manually grab all the timings from the notebook and drop them in this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47cd820-e12b-4ad7-85f3-d1093d5f0486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# get values from code\n",
    "d = { 'loops': [3130], 'joblib': [2560], 'inner compiled': [233], 'parallel': [87] }\n",
    "df = pd.DataFrame (data=d)\n",
    "df.head()\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ac779-4252-401b-9f1a-78c173130d53",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conclusions:\n",
    "\n",
    "  * JIT Compilation is a powerful tool\n",
    "  * JIT can only speed up the code that is compiled \n",
    "  * Numba has parallelization primitives for embarrassingly parallel code (only)\n",
    " \n",
    "This is a pretty clear reminder that parallelism is only one of many speedup tools. It turns out to be useful here after we are running on compiled code, but in the big picture, compiling code to get access to ILP is equally important.\n",
    "\n",
    "Numba gives access to vectorized code, but it has been hard to isolate. I'm working on it for another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0729a43-c978-4434-915d-7ec07198f09b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
