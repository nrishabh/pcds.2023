{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75c8ac9-b947-4dc9-9eb8-3bcd2c9662eb",
   "metadata": {},
   "source": [
    "### Activity 7: Communicating Ray Actors\n",
    "\n",
    "This is a short exercise to demonstrate how actors can communicate through remote oids.\n",
    "We are going to break the actors of the ImageNet classification [Example 24](../../examples/24_ex_ray_actors.ipynb) into \n",
    "two actors: one that transforms the image into an ResNet50 compatible tensor and one that takes\n",
    "the tensor as input and returns the classification. \n",
    "\n",
    "You have been given two class files that have been written to be instantiated as Ray actors:\n",
    "  * [rayresnet50_normalize](./rayresnet50_normalize.py)\n",
    "  * [rayresnet50_classify](./rayresnet50_classify.py)\n",
    "\n",
    "To complete the exercise you need to populate the following driver code.  Then answer the questions.\n",
    "\n",
    "Data is from https://github.com/EliSchwartz/imagenet-sample-images.\n",
    "\n",
    "Note: check your ouput to make sure that the predictions match the input file. This classifier should be over 90% correct. You need to be careful to match the return OIDs with files. **Include the cell output in submitted notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f39ff1e-03fe-4853-8039-d2dea50c019f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rayresnet50_normalize import RRN50Normalize\n",
    "from rayresnet50_classify import RRN50Classify\n",
    "import ray\n",
    "import time\n",
    "import os\n",
    "\n",
    "num_actors=4\n",
    "\n",
    "# script to drive parallel program\n",
    "ray.init(num_cpus=num_actors, ignore_reinit_error=True)\n",
    "\n",
    "### instantiate 4 normalization actors\n",
    "normalize_actors = [RRN50Normalize.remote() for _ in range(num_actors)]\n",
    "\n",
    "### instantiate 4 classification actors\n",
    "classify_actors = [RRN50Classify.remote() for _ in range(num_actors)]\n",
    "\n",
    "directory = 'data/'\n",
    "files = os.listdir(directory)\n",
    "\n",
    "start_time = time.time()  # Get the current time\n",
    "\n",
    "oids = list()\n",
    "\n",
    "for i in range(len(files)):\n",
    "    if files[i].endswith(\".JPEG\"):\n",
    "        file_path = os.path.join(directory, files[i])\n",
    "\n",
    "        ### call remote to normalize image into tensor\n",
    "        tensor_oid = normalize_actors[i % num_actors].normalize_image.remote(file_path)\n",
    "        \n",
    "        ### call remote to classify tensor\n",
    "        classify_oid = classify_actors[i % num_actors].classify_image.remote(tensor_oid)\n",
    "        \n",
    "        ### store the oids needed to complete the computation\n",
    "        oids.append(classify_oid)\n",
    "        \n",
    "preds = list()\n",
    "\n",
    "for i in range(len(files)):\n",
    "    try:\n",
    "        ### collect results for each file in a variable preds\n",
    "        preds.append(ray.get(oids[i]))\n",
    "        print(f\"Filename {files[i]}: predictions {preds[-1]}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "end_time = time.time()  # Get the current time again\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time: \", execution_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f80ddb-2308-4a0f-970b-8121ab1de586",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* Question 1: Does the computation for a single input file (normalization and classification) run in serial or parallel?  If serially, how is the dependency enforced?  \n",
    "\n",
    "    **Answer**: The computation for a single file, involving normalization and classification, is executed serially within a parallel framework. This serial execution is enforced by data dependency: the classification of an image cannot begin until its normalization is complete. We utilize Ray to parallelize these operations across multiple files, allowing different files to be normalized and classified simultaneously by different actors. Thus, while each file is processed serially, multiple files undergo this process in parallel.\n",
    "\n",
    "* Question 2: Does the computation of different files run in serial or parallel?  If parallel, explain why they are independent.  \n",
    "\n",
    "    **Answer**: The computation of different files runs in parallel, not in serial. By creating multiple `normalize_actors` and `classify_actors`, we distribute the tasks of normalizing and classifying images across different CPU cores. Each actor handles a subset of the files independently, allowing simultaneous processing. The independence of these tasks is inherent, as each image's normalization and classification do not depend on the results of other images, making them suitable for parallel execution.\n",
    "\n",
    "* Question 3: Your computation needs to collect return identifiers for the classification objects. It is not necessary to collect the OIDs of the normalization function in the driver code. Why?  \n",
    "\n",
    "    **Answer**: In Ray, the output of one actor method can directly be used as the input for another actor method, eliminating the need to collect intermediate Object IDs in the driver code. The normalization actors' outputs are directly passed to the classification actors. Thus, only the final classification results (OIDs from classify_actors) need to be collected by the driver for further processing.\n",
    "\n",
    "* Question 4: At any given point in time, how many actors are running and what are they doing?  \n",
    "\n",
    "    **Answer**: At any given time, up to eight actors (four normalization actors and four classification actors) can be running concurrently. The normalization actors are responsible for normalizing images into tensors, while the classification actors classify these tensors. The number of active actors depends on the number of files being processed and their distribution across the actors, given the round-robin scheduling (`i % num_actors`).\n",
    "\n",
    "* Question 5: Is this implementation faster or slower than doing the normalization and classification in one actor?  Can you think of a situation in which it would be faster to do them together?  (By situation, I mean data properties or target hardware system on which this would be preferable.)  \n",
    "\n",
    "    **Answer**: This implementation, which uses separate actors for normalization and classification, can be faster due to parallel processing, especially if normalization and classification are computationally intensive and independent tasks. However, if the tasks share significant data or if inter-actor communication overhead is high, combining them into one actor could be faster, particularly on systems with limited processing cores or slower inter-process communication capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9ea7e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
